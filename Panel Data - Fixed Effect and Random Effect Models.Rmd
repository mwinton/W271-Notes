---
title: "Panel Data - Fixed Effect and Random Effect Models"
author: "Michael Winton"
date: \today
output:
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: inline
header-includes: \usepackage{amsmath}
geometry: margin=1in
fontsize: 11pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(digits=4, fig.height=3.5, warn=FALSE)

library(car)
library(GGally)
library(plm)
library(Ecdat)  # sample datasets
library(stargazer) # summarize models
library(wooldridge)  # sample datasets
```

## Fixed Effect Transformation

Whereas the First Difference models eliminate the time-invariant unobserved variables by subtracting one observation from another, the Fixed Effect Transformation involves subtracting out the individual's average (over time) from each observation.

If we have observations from $i=1,2,...n$ individuals and $t=1,2,...T$ periods:

$$y_{it} = \beta_0 + \beta_1 x_{it} + a_i + \epsilon_{it}$$
Averaging individuals over time:

$$\bar{y}_i = \beta_0 + \beta_1 \bar{x}_i + \bar{a}_i + \bar{\epsilon}_{it} $$

Subtracting, we get:

$$ y_{it} - \bar{y}_i =  \beta_1 (\bar{x}_i - \bar{x}_i) +  (\epsilon_{it} - \bar{\epsilon}_{it}) $$
Notice that both the intercept $\beta_0$ and the time-invariant unobserved variables $a_i$, also known as the _unobserved individual heterogeneity_ have dropped out.  We refer to $y_{it} - \bar{y}_i$ as the _demeaned_ response variable.

The more general form of the equation with $k$ explanatory variables is:

$$ y_{it} - \bar{y}_i =  \beta_1 (\bar{x}_{i1} - \bar{x}_{i1}) +  \beta_2 (\bar{x}_{i2} - \bar{x}_{i2}) +  ... + \beta_k (\bar{x}_{ik} - \bar{x}_{ik}) +  + (\epsilon_{it} - \bar{\epsilon}_{it}) $$

As with the First Difference transformation, any explanatory variables that are constant in the dataset will be dropped out, too.  Variables with very little variation will become almost constant after transformation.  _Interactions_ with time-invariant variables can be estimated through use of (time) dummy variables.  However, if a full set of time dummies is included, then its impossible to estimate the effect of deterministic time-varying variables because they can't be distinguished from aggregate time effect.

### Estimating Fixed Effects model with OLS

This time-demeaned equation can then be estimated by OLS.  It uses time variation _within_ each of the cross-sectional units (subjects) in the dataset.  Because of this, the fixed effect transformation is also called _within transformation_. CLM assumptions are still required in order for estimators to be consistent.  $\epsilon_{it}$ must have zero-conditional mean ($E(\epsilon_{it} | X_i, a_i)=0 \  \forall t$), homoskedasticity, and serially uncorrelated across $t$.

The poolability test in `pooltest` has a null hypothesis that the slope coefficient is constant across time.  The serial correlation test in `pbgtest` has a null hypothesis of _no_ serial correlation.  
```{r}
data("Grunfeld")
head(Grunfeld)

# test for poolability
znp <- pvcm(inv ~ value + capital, data=Grunfeld, model='within')
zplm <- plm(inv ~ value + capital, data=Grunfeld)
pooltest(zplm, znp)

# test for serial correlation
grun_panel <- pdata.frame(Grunfeld, index=c('firm','year'))
grun_fe <- plm(inv ~ value + capital, data=grun_panel, model='within')
pbgtest(grun_fe, order=2)
```

In this case, we strongly reject the null hypothesis for poolability and for no serial correlation.


## Between Estimators

We do not focus on the coefficients of the "average" equation above, as they are biased when the observed explanatory variables $x$ are correlated with the unobserved fixed effect $a_i$.  Additionally, these don't use the panel data efficiently, as they lose the time element.

If we think the explanatory variables and the unobserved fixed effect are _uncorrelated_, we would be better off using the **random effect model**.

## The `plm` function for panel data modeling

The `plm` function supports 4 estimation methods:

  1. pooled OLS (model='pooling')
  2. fixed effects (model='within')
  3. random effects (model='random')
  4. first differences (model='fd')
  5. between (model='between')

It also supports unbalanced panels, two-way effects, and instrumental variables.  For example, if you have a model $y$ is related to $x1$ and $x2$ endogenous variables, $x3$ exogenous variable,and $z1$ and $z2$ external instructions, it could specified as either:

    - y ~ x1 + x2 + x3 | x3 + z1 + z2
    - y ~ x1 + x2 + x3 | x. -x1 -x2 + z1 + z2

The `plm` function expects data in a _person-period_ format (ie. one row per person per time period observation).  The `pdata.frame` call is used to add an index to a data frame.

### Example: job training effect on manufacturing scrap rate

```{r}
data(jtrain)  # from Wooldridge
str(jtrain)
table(jtrain$year)
# table(jtrain$fcode)
# head(jtrain,12)
```

We see there are 157 individuals in the panel.  We have indicator variables for `d88` and `d89`.

```{r}
# split the dataframe by year
# technique for EDA, rather than a technique for panel data analysis
tmp <- split.data.frame(jtrain, as.factor(jtrain$year))
jtrain_87 <- tmp$'1987'
jtrain_88 <- tmp$'1988'
jtrain_89 <- tmp$'1989'
```
### Example: (Naive) OLS Method - applied to a single year

Warning: OLS models don't tell us anything about change over time, nor do they remove the time-invariant unobserved variables.  As a result, it's possible to have omitted variable bias. Here, we just do a naive model for a single year subset of our data (not recommended).

```{r}
# let's ignore 1988 and 1989, and estimate a model based on 1987
# grant = job training grant
# grant_1 = 1-year lagged training grant
# scrap = # units scrapped
# "l" columns indicate logs

# look at effect of grant and grant_1 (=lag with k=1)
jtrain89_ols <- lm(lscrap ~ grant + grant_1, data=jtrain_89)
summary(jtrain89_ols)

# effect of the grant on the scrap rate (need to exponentiate)
exp(jtrain89_ols$coefficients[2]) - 1
```
The model shows that the traininggrant, and the lagged grant ($k=1$) both have positive impacts on the (log) scrap rate.  The grant is predicted to _increase_ the firm's scrap rate by 56%!  This is counterintuitive; we need to try a panel data model.


### Example: First-Difference Method

Now let's use a proper panel model using `plm`.  

```{r}
# specify index as (individuals, periods)
jtrain_panel <- pdata.frame(jtrain, index=c('fcode','year'))
# show a sample to see how index is applied
str(jtrain_panel$scrap)

# first difference model
jtrain_g_fd <- plm(lscrap ~ grant + grant_1, data=jtrain_panel, model='fd')
summary(jtrain_g_fd)
```
Observe that the directional effect of the coefficients is as expected - job training reduces scrap rate.

### Example: Fixed Effects Method

Alternately, we can apply the FE method.

```{r}
# fixed effects model of grants
jtrain_g_fe <- plm(lscrap ~ d88 + d89 + grant + grant_1, data=jtrain_panel, model='within')
summary(jtrain_g_fe)

# check effect of grant on scrap
exp(jtrain_g_fe$coefficients[3])-1
exp(jtrain_g_fe$coefficients[4])-1
```
Note the negative sign on the coefficients for the effect of training grants -- job training in 1988 reduces scrap rate in 1989 by 22% (more aligned with expectations).  Job training in 1987 reduces scrap rate in 1989 by 34%.

## Random Effects Models

The random effects model includes all of the assumptions of the fixed effects model, but also includes the strong requirement that $a_i$ is independent of _all_ explanatory variables in _all_ time periods.

When we can't meet that strong requirement of independence of $a_i$, we used the fixed effect model as a tool for eliminating omitted variable bias.  If we do meet the requirement that $a_i$ is independent, we can get consistent OLS estimators of the regression coefficients $\hat{\beta_j}$ from a single cross-section of our data; we don't need the whole panel.  The value of the random effects model doesn't come in here.

As we did earlier for pooled OLS, we rewrite the equation in a _composite error_ form:

$$ y_{it} = \beta_0 + \beta_1 x_{1it} + ... + \beta_k x_{kit}+ \mu_{it}$$
where in reality $\mu_{it} = a_i + \epsilon_{it}$, and $i=1...n$ and $t=1...T$.  Because $a_i$ is contained in the composite error term in _each time period_, $\mu_{it}$ is, _by definition_, serially correlated. This serial correlation is given by:

$$ Corr(\mu_{it}, \mu_{is}) = \sigma_a^2 / (\sigma_a^2 + \sigma_\epsilon^2), t \ne s$$

This serial correlation is by definition positive and can be substantial.  Since pooled OLS _ignores this serial correlation_, its standard errors will be incorrect and test statistics invalid, even if $a_i$ is uncorrelated with the explanatory variables. The value of the random effects model is that it allows us to overcome this serial correlation.

The random effects model uses Generalized Least Squares (rather than OLS).  For GLS to have good properties, we need a "short panel", meaning a large $N$ but a small number of $T$ periods.  The GLS transformation that eliminates serial error correlation is (with $\lambda$ between 0-1):

$$ \lambda = \bigg[ \frac{\sigma_e^2}{\sigma_e^2 + T \sigma_a^2} \bigg]^{1/2}$$

The transformed model becomes (where the overbar indicates time averages) :

$$ y_{it} - \lambda \bar{y}_i = \beta_0 (1 - \lambda) + \beta_1(x_{1it}- \bar{x}_{1i}) + ... + \beta_k (x_{kit}- \bar{x}_{ki}) + (\mu_{it} - \lambda \bar{\mu}_i)$$

So, in words, whereas the fixed effects model subtracts the _entire_ time averages from the corresponding variables, the random effects model subtracts a _fraction_ of those time averages, with that fraction $\lambda$ being a function of $\sigma_e, \sigma_a, T$.  The GLS estimator is simply the pooled estimator of this transformed equation.

In practice, we will not know the actual $\sigma_e, \sigma_a$, so we will need to estimate $\lambda$ based on pooled OLS or fixed effect residuals.  The `plm` package will automatically calculate the random effect estimator $\hat{\lambda}$.  Under random effect assumptions, this estimator $\hat{\lambda}$ will be consistent and asymptotically normally distributed (but not unbiased) for large $N$ and fixed $T$.  Their behavior with large $T$ and small $N$ is largely unknown.

The $\hat{\lambda}$ estimator ranges between 0 and 1.  If  $\hat{\lambda}=0$, then the model is the same as pooled OLS; if $\hat{\lambda}=1$, then the model is the same as the fixed effects model.  So, if we obtain  $\hat{\lambda}$ close to zero, that indicates the unobserved effect $a_i$ is relatively unimportant.

One important benefit of the random effects model (contrasted against the fixed effects model) is that it allows for time-independent explanatory variables.  With the random effects model, they do not get completely subtracted out.

## Hausman test for validity of RE assumptions

We run the Hausman test by estimating both fixed effects and random effects models, then passing them to the R function `phtest`.  A rejection of the null hypothesis indicates that the assumptions required to use the random effects model are not met, and we should instead use the fixed effects model.

A failure to reject means either that the RE and FE estimates are sufficiently similar that it doesn't matter which we use, or that sampling variation is so large in the FE estimates that we cannot conclude that practically significant differences are statistically significant.  (In this latter case, we would be uncertain whether we have enough information to estimate the coefficients.)

## Example: comparing models with wage data

In reality, when we are estimating either FE or RE models, it's usually informative to also run a pooled OLS model.  Comparing the results of the 3 models can help identify the nature of biases left completely in the composite error term (pooled OLS), or partially so (RE).  Just don't forget that because of serial correlation in the error term, standard errors obtained from pooled OLS as usually invalid.

Let's do an example with wage data vs. education and race dummies, which drop out of the FE model since they're constant over time, as well as time-varying variables for experience (and also its square), union, and married.

```{r}
data("wagepan")  # this is a short panel (545 individuals, 8 periods)
wage_plm <- pdata.frame(wagepan, index=c('nr', 'year'))
mod_pooled <- plm(lwage ~ educ + black + hisp + exper + exper^2 + married + union, 
                  data=wage_plm, model='pooling')
mod_re <- plm(lwage ~ educ + black + hisp + exper + exper^2 + married + union, 
                  data=wage_plm, model='random')
mod_fe <- plm(lwage ~ educ + black + hisp + exper + exper^2 + married + union, 
                  data=wage_plm, model='within')
stargazer(mod_pooled, mod_re, mod_fe, type="text", omit.stat='f',
          column.labels=c('Pooled','RE','FE'))

# perform the Hausman test
phtest(mod_fe, mod_re)
```
Observations:

    - Coefficients for education, black, and hispanic are similar for pooled and RE
    - Pooled OLS standard errors underestimate the true errors due to serial correlation
    - Compared to pooled model, marriage and union effects are much smaller in RE model
    - In FE model, (which eliminates unboserved fixed effects), marriage and union effects both drop substantially
    - The Hausman Test indicates that the assumptions for RE are not met; we should use FE model
    
## Takeaways: Fixed Effects vs. Random Effects

Because FE model allows for arbitrary correlation between $a_i$ and explanatory variables (RE does not), FE is considered a more convincing tool for determining "ceteris paribus" effects.  However, random effects models are particularly important if the explanatory variables are constant over time.  When justified, the RE model is generally more _efficient_ (ie. needs fewer observations to achieve a given performance) than pooled OLS. 
    
Just keep in mind that the assumption that $a_i$ is uncorrelated with all explanatory variables over time is often not a reasonable assumption.    If we know (or want to allow) that our unobserved effect is correlated with any explanatory variables - which is often the reason for using panel data in the first place - we should not use RE; use FE or FD models instead.  When we use RE, we should give substantial reasons why we consider it valid.  We should also use the Hausman test for the full set of RE assumptions.
